{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a897e393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 06:19:50.776669: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-18 06:19:50.807554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-18 06:19:50.807575: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-18 06:19:50.808399: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-18 06:19:50.813455: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-18 06:19:51.446494: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "import pickle\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e881464",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 20\n",
    "IMAGE_HEIGHT = 512\n",
    "IMAGE_WIDTH = 512\n",
    "MAX_VECTORS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715d5a50",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d05499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 06:19:55.479525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22502 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:19:00.0, compute capability: 8.6\n",
      "2024-06-18 06:19:55.479947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22502 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:8d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "def iou_score(y_pred, y_true, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n",
    "    iou = (intersection + smooth)/(union + smooth)\n",
    "    return iou\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "custom_objects = {\"dice_coef_loss\": dice_coef_loss, 'iou_score': iou_score}\n",
    "\n",
    "with keras.saving.custom_object_scope(custom_objects):\n",
    "    model = load_model(\"models/r2u_attention_80e.h5\")\n",
    "    \n",
    "with keras.saving.custom_object_scope(custom_objects):\n",
    "    catheter_model = load_model(\"models/catheter_detect.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f80249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(img, pred_img):\n",
    "    match_img = pred_img*img\n",
    "    return match_img\n",
    "\n",
    "# function to average color\n",
    "def average(img, i, j, r):\n",
    "  sum = 0\n",
    "  for x in range(i - r, i + r + 1):\n",
    "    for y in range(j -r, j + r + 1):\n",
    "      sum += img[x][y]\n",
    "  return sum/((2*r + 1)**2)\n",
    "\n",
    "# function to match the segmentation back to the origin image, but we just get a square area\n",
    "def square_match(img, pred_img, target):\n",
    "  # get top, right, bottom, left boundary\n",
    "\n",
    "  top_flat = 0\n",
    "  top_index = 512\n",
    "  for i in range(0, 510):\n",
    "    for j in range(0, 510):\n",
    "      if average(pred_img, i, j, 2) > 0.7:\n",
    "        top_flat = 1\n",
    "        top_index = max(0, i - 10)\n",
    "        break\n",
    "    if top_flat == 1:\n",
    "      break\n",
    "\n",
    "  right_flat = 0\n",
    "  right_index = 0\n",
    "  for j in reversed(range(0, 510)):\n",
    "    for i in range(0, 510):\n",
    "      if average(pred_img, i, j, 2) > 0.7:\n",
    "        right_flat = 1\n",
    "        right_index = min(j + 10, 512)\n",
    "        break\n",
    "    if right_flat == 1:\n",
    "      break\n",
    "\n",
    "  bottom_flat = 0\n",
    "  bottom_index = 0\n",
    "  for i in reversed(range(0, 510)):\n",
    "    for j in range(0, 510):\n",
    "      if average(pred_img, i, j, 2) > 0.7:\n",
    "        bottom_flat = 1\n",
    "        bottom_index = min(512, i + 10)\n",
    "        break\n",
    "    if bottom_flat == 1:\n",
    "      break\n",
    "\n",
    "  left_flat = 0\n",
    "  left_index = 512\n",
    "  for j in range(0, 510):\n",
    "    for i in range(0, 510):\n",
    "      if average(pred_img, i, j, 2) > 0.7:\n",
    "        left_flat = 1\n",
    "        left_index = max(0, j - 10)\n",
    "        break\n",
    "    if left_flat == 1:\n",
    "      break\n",
    "\n",
    "  if target == \"full\":\n",
    "    for i in range(512):\n",
    "      for j in range(512):\n",
    "        if i < top_index or i > bottom_index or j < left_index or j > right_index:\n",
    "          img[i][j] = 0\n",
    "\n",
    "  if target == \"crop\":\n",
    "    if left_index == 512 and top_index == 512 and right_index == 0 and bottom_index == 0:\n",
    "      return 0\n",
    "    else:\n",
    "      return img[top_index:bottom_index, left_index:right_index]\n",
    "\n",
    "  return img\n",
    "\n",
    "def predict_one_image(img, model):\n",
    "  resized_img = cv2.resize(img, (512, 512))\n",
    "  X = np.reshape(resized_img, (1, resized_img.shape[0], resized_img.shape[1], 1))\n",
    "  normalized_X = X/255\n",
    "  normalized_X = np.rollaxis(normalized_X, 3, 1)\n",
    "  pred_y = model.predict(normalized_X, verbose=0)\n",
    "  pred_y[pred_y > 0.5] = 1\n",
    "  pred_y[pred_y != 1] = 0\n",
    "  pred_img = np.reshape(pred_y[0]*255, (512, 512))\n",
    "  match_img = pred_img*resized_img\n",
    "  return pred_img, match_img\n",
    "\n",
    "def remove_catheter(image):\n",
    "    vessel_img, _ = predict_one_image(image, model)\n",
    "    catheter_img, _ = predict_one_image(image, catheter_model)\n",
    "    subtract_image = vessel_img - catheter_img\n",
    "    _, binary = cv2.threshold(subtract_image, 50, 255, cv2.THRESH_BINARY)\n",
    "    binary = binary.astype(np.uint8)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    largest_contour = find_largest_contour(contours)\n",
    "    mask = np.zeros_like(binary)\n",
    "    cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "    vessel_img = cv2.bitwise_and(subtract_image, subtract_image, mask=mask)\n",
    "    resized_img = cv2.resize(img, (512, 512))\n",
    "    return vessel_img/255., resized_img*vessel_img/255.\n",
    "\n",
    "def get_vessel(image):\n",
    "    vessel_img, _ = predict_one_image(image, model)\n",
    "    subtract_image = vessel_img \n",
    "    resized_img = cv2.resize(img, (512, 512))\n",
    "    return vessel_img/255., resized_img*vessel_img/255.\n",
    "\n",
    "def find_largest_contour(contours):\n",
    "    max_contour = None\n",
    "    max_area = 0\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_contour = contour\n",
    "    return max_contour\n",
    "\n",
    "def neighbours(x,y,image):\n",
    "    img = image\n",
    "    x_1, y_1, x1, y1 = x-1, y-1, x+1, y+1\n",
    "    return [ img[x_1][y], img[x_1][y1], img[x][y1], img[x1][y1],     # P2,P3,P4,P5\n",
    "                img[x1][y], img[x1][y_1], img[x][y_1], img[x_1][y_1] ]    # P6,P7,P8,P9\n",
    "\n",
    "def transitions(neighbours):\n",
    "    n = neighbours + neighbours[0:1]      # P2, P3, ... , P8, P9, P2\n",
    "    return sum( (n1, n2) == (0, 1) for n1, n2 in zip(n, n[1:]) )  # (P2,P3), (P3,P4), ... , (P8,P9), (P9,P2)\n",
    "\n",
    "def zhangSuen(image):\n",
    "    Image_Thinned = image.copy()  # deepcopy to protect the original image\n",
    "    changing1 = changing2 = 1        #  the points to be removed (set as 0)\n",
    "    while changing1 or changing2:   #  iterates until no further changes occur in the image\n",
    "        # Step 1\n",
    "        changing1 = []\n",
    "        rows, columns = Image_Thinned.shape               # x for rows, y for columns\n",
    "        for x in range(1, rows - 1):                     # No. of  rows\n",
    "            for y in range(1, columns - 1):            # No. of columns\n",
    "                P2,P3,P4,P5,P6,P7,P8,P9 = n = neighbours(x, y, Image_Thinned)\n",
    "                if (Image_Thinned[x][y] == 1     and    # Condition 0: Point P1 in the object regions\n",
    "                    2 <= sum(n) <= 6   and    # Condition 1: 2<= N(P1) <= 6\n",
    "                    transitions(n) == 1 and    # Condition 2: S(P1)=1\n",
    "                    P2 * P4 * P6 == 0  and    # Condition 3\n",
    "                    P4 * P6 * P8 == 0):         # Condition 4\n",
    "                    changing1.append((x,y))\n",
    "        for x, y in changing1:\n",
    "            Image_Thinned[x][y] = 0\n",
    "        # Step 2\n",
    "        changing2 = []\n",
    "        for x in range(1, rows - 1):\n",
    "            for y in range(1, columns - 1):\n",
    "                P2,P3,P4,P5,P6,P7,P8,P9 = n = neighbours(x, y, Image_Thinned)\n",
    "                if (Image_Thinned[x][y] == 1   and        # Condition 0\n",
    "                    2 <= sum(n) <= 6  and       # Condition 1\n",
    "                    transitions(n) == 1 and      # Condition 2\n",
    "                    P2 * P4 * P8 == 0 and       # Condition 3\n",
    "                    P2 * P6 * P8 == 0):            # Condition 4\n",
    "                    changing2.append((x,y))\n",
    "        for x, y in changing2:\n",
    "            Image_Thinned[x][y] = 0\n",
    "    return Image_Thinned\n",
    "\n",
    "def distance(x1,y1,x2,y2):\n",
    "  return np.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "\n",
    "def min_distance(x,y, vector, limit):\n",
    "  if limit > 0:\n",
    "    d = [distance(x, y, vector[i][0],vector[i][1]) for i in range(limit)]\n",
    "    d.sort()\n",
    "    return d[0]\n",
    "  return 1000\n",
    "\n",
    "def vectorize_one_image_using_center_line(img):\n",
    "  vector = np.zeros((MAX_VECTORS, 3), dtype=np.float32)\n",
    "  STEP = 5\n",
    "  resized_img = cv2.resize(img, (512, 512))\n",
    "  pred_img, match_img = get_vessel(img)\n",
    "\n",
    "  centerline = zhangSuen(pred_img.astype(int))\n",
    "\n",
    "  all_zeros = np.all(pred_img == 0)\n",
    "  if all_zeros:\n",
    "    return np.zeros((MAX_VECTORS, 3)), None\n",
    "  img_with_rectangles = cv2.cvtColor(match_img, cv2.COLOR_GRAY2BGR)\n",
    "  centerline_with_rect = cv2.cvtColor(centerline.astype(np.float32)*255, cv2.COLOR_GRAY2BGR)\n",
    "  index = 0\n",
    "  WS12 = WINDOW_SIZE//2\n",
    "\n",
    "  for y in range(0, IMAGE_HEIGHT, STEP):\n",
    "      for x in range(0, IMAGE_WIDTH, STEP):\n",
    "          window = centerline[y:y + STEP, x:x + STEP]\n",
    "          x_arr, y_arr = np.where(window==1)\n",
    "          if len(x_arr) > 2:\n",
    "            # calculate the center point of window\n",
    "            x_w = int(x_arr.mean()) + x\n",
    "            y_w = int(y_arr.mean()) + y\n",
    "\n",
    "            # get closest window from x_w, y_w\n",
    "            m_distance = min_distance(x_w, y_w, vector, index)\n",
    "            # check overlap among window\n",
    "            if m_distance >  WS12 * 1.5:\n",
    "              window = pred_img[y_w - WS12 : y_w + WS12, x_w - WS12 : x_w + WS12]\n",
    "              upper_left = (x_w - WS12, y_w - WS12)\n",
    "              lower_right = (x_w + WS12, y_w + WS12)\n",
    "              # disable area that we already used\n",
    "              centerline[upper_left[1]:lower_right[1]+1,upper_left[0]:lower_right[0]+1] = 0\n",
    "\n",
    "              cv2.rectangle(img_with_rectangles, upper_left, lower_right, (0, 255, 0), 1)\n",
    "              cv2.rectangle(centerline_with_rect, upper_left, lower_right, (0, 255, 0), 1)\n",
    "\n",
    "              average_color = np.sum(window)\n",
    "              vector[index] = np.array([x_w, y_w, average_color])\n",
    "              index+=1\n",
    "              if index>=MAX_VECTORS:\n",
    "                break\n",
    "      if index>=MAX_VECTORS:\n",
    "        break\n",
    "  return vector, img_with_rectangles, centerline_with_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8345c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_one_image_using_center_line(img):\n",
    "    vector = np.zeros((MAX_VECTORS, 3), dtype=np.float32)\n",
    "    STEP = 5\n",
    "    RESIZE_DIM = (512, 512)\n",
    "    resized_img = cv2.resize(img, RESIZE_DIM)\n",
    "    pred_img, match_img = get_vessel(img)\n",
    "\n",
    "    centerline = zhangSuen(pred_img.astype(int))\n",
    "\n",
    "    if np.all(pred_img == 0):\n",
    "        return vector, None\n",
    "\n",
    "    img_with_rectangles = cv2.cvtColor(match_img, cv2.COLOR_GRAY2BGR)\n",
    "    centerline_with_rect = cv2.cvtColor(centerline.astype(np.float32) * 255, cv2.COLOR_GRAY2BGR)\n",
    "    index = 0\n",
    "    WS12 = WINDOW_SIZE // 2\n",
    "    IMAGE_DIM = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "\n",
    "    for y in range(0, IMAGE_DIM[0], STEP):\n",
    "        for x in range(0, IMAGE_DIM[1], STEP):\n",
    "            window = centerline[y:y + STEP, x:x + STEP]\n",
    "            if np.count_nonzero(window) > 2:\n",
    "                y_arr, x_arr = np.where(window == 1)\n",
    "                x_w = int(x_arr.mean()) + x\n",
    "                y_w = int(y_arr.mean()) + y\n",
    "\n",
    "                if min_distance(x_w, y_w, vector, index) > WS12 * 1.5:\n",
    "                    upper_left = (max(0, x_w - WS12), max(0, y_w - WS12))\n",
    "                    lower_right = (min(IMAGE_WIDTH, x_w + WS12), min(IMAGE_HEIGHT, y_w + WS12))\n",
    "                    \n",
    "                    if (lower_right[0] - upper_left[0]) <= 0 or (lower_right[1] - upper_left[1]) <= 0:\n",
    "                        continue\n",
    "\n",
    "                    window = pred_img[upper_left[1]:lower_right[1], upper_left[0]:lower_right[0]]\n",
    "                    centerline[upper_left[1]:lower_right[1], upper_left[0]:lower_right[0]] = 0\n",
    "\n",
    "                    cv2.rectangle(img_with_rectangles, upper_left, lower_right, (0, 255, 0), 1)\n",
    "                    cv2.rectangle(centerline_with_rect, upper_left, lower_right, (0, 255, 0), 1)\n",
    "\n",
    "                    average_color = window.sum()\n",
    "                    vector[index] = [x_w, y_w, average_color]\n",
    "                    index += 1\n",
    "\n",
    "                    if index >= MAX_VECTORS:\n",
    "                        return vector, img_with_rectangles\n",
    "\n",
    "    return vector, img_with_rectangles, centerline_with_rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c9104bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_boxes(row):\n",
    "    width_scale = 512 / row['width']\n",
    "    height_scale = 512 / row['height']\n",
    "    \n",
    "    row['xmin'] = int(row['xmin'] * width_scale)\n",
    "    row['ymin'] = int(row['ymin'] * height_scale)\n",
    "    row['xmax'] = int(row['xmax'] * width_scale)\n",
    "    row['ymax'] = int(row['ymax'] * height_scale)\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d69922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_window_overlap(x, y, window_size, box):\n",
    "    xmin = x - window_size / 2\n",
    "    ymin = y - window_size / 2\n",
    "    xmax = x + window_size / 2\n",
    "    ymax = y + window_size / 2\n",
    "    \n",
    "    box_xmin, box_ymin, box_xmax, box_ymax = box\n",
    "    \n",
    "    if (xmin < box_xmax and xmax > box_xmin and\n",
    "        ymin < box_ymax and ymax > box_ymin):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e40551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = df_train.filename.values\n",
    "# vectors = np.zeros((len(filenames), 40, 3))\n",
    "# labels = np.zeros((len(filenames), 40))\n",
    "# boxes = df_train[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
    "\n",
    "# for index, filename in tqdm(enumerate(filenames)):\n",
    "#     img = cv2.imread(os.path.join(\"data\", filename), 0)\n",
    "#     resized_img = cv2.resize(img, (512, 512))\n",
    "#     pred_img, match_img = get_vessel(img)\n",
    "#     skeletion = skeletonize(pred_img.astype(int))\n",
    "#     vector, img_with_rectangles, centerline_with_rect = vectorize_one_image_using_center_line(img)\n",
    "#     label = []\n",
    "#     for v in vector:\n",
    "#         x, y, color = v\n",
    "#         label.append(is_window_overlap(x, y, WINDOW_SIZE//2, boxes[index]))\n",
    "#     vectors[index] = vector\n",
    "#     label = np.array(label)\n",
    "#     labels[index] = label\n",
    "#     break\n",
    "# #     np.save(\"label.npy\", labels)\n",
    "# #     np.save(\"vector.npy\", vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5848989",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(\"label.npy\")\n",
    "vectors = np.load(\"vector.npy\")\n",
    "vectors = vectors[:546]\n",
    "labels = labels[:546]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0339c099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_labels.csv')\n",
    "filenames = df_train.filename.values[:546]\n",
    "images_list = np.zeros((len(filenames), 40, 20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae977b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2024-06-18 06:20:08.020214: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "546it [00:34, 15.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, filename in tqdm(enumerate(filenames)):\n",
    "    img = cv2.imread(os.path.join(\"data\", filename), 0)\n",
    "    resized_img = cv2.resize(img, (512, 512))\n",
    "    pred_img, match_img = get_vessel(img)\n",
    "    vector = vectors[index]\n",
    "    images = np.zeros((40, 20, 20))\n",
    "    for i, v in enumerate(vector):\n",
    "        x, y, pixel_count = v\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        small_image = pred_img[y-10:y+10, x-10:x+10]\n",
    "        if small_image.shape[0]!=20 or small_image.shape[1]!=20:\n",
    "            continue\n",
    "        images[i] = small_image\n",
    "    images_list[index] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "359b8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"images_list.npy\", images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369ab94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546, 40, 20, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_list = np.load(\"images_list.npy\")\n",
    "images_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eae8df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_accuracy(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    correct_predictions = tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32), axis=-1)\n",
    "    accuracy = correct_predictions / tf.cast(tf.shape(y_true)[-1], tf.float32)\n",
    "    return tf.reduce_mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa680d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "nINF = -100.0\n",
    "\n",
    "class TwoWayLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, Tp=4.0, Tn=1.0, name=\"two_way_loss\"):\n",
    "        super(TwoWayLoss, self).__init__(name=name)\n",
    "        self.Tp = Tp\n",
    "        self.Tn = Tn\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        class_mask = tf.reduce_any(y_true > 0, axis=0)\n",
    "        sample_mask = tf.reduce_any(y_true > 0, axis=1)\n",
    "\n",
    "        # Calculate hard positive/negative logits\n",
    "        pmask = tf.where(y_true > 0, 0.0, nINF)\n",
    "        plogit_class = tf.reduce_logsumexp(-y_pred / self.Tp + pmask, axis=0) * self.Tp\n",
    "        plogit_sample = tf.reduce_logsumexp(-y_pred / self.Tp + pmask, axis=1) * self.Tp\n",
    "        \n",
    "        plogit_class = tf.boolean_mask(plogit_class, class_mask)\n",
    "        plogit_sample = tf.boolean_mask(plogit_sample, sample_mask)\n",
    "    \n",
    "        nmask = tf.where(y_true == 0, 0.0, nINF)\n",
    "        nlogit_class = tf.reduce_logsumexp(y_pred / self.Tn + nmask, axis=0) * self.Tn\n",
    "        nlogit_sample = tf.reduce_logsumexp(y_pred / self.Tn + nmask, axis=1) * self.Tn\n",
    "\n",
    "        nlogit_class = tf.boolean_mask(nlogit_class, class_mask)\n",
    "        nlogit_sample = tf.boolean_mask(nlogit_sample, sample_mask)\n",
    "\n",
    "        return tf.reduce_mean(tf.nn.softplus(nlogit_class + plogit_class)) + \\\n",
    "               tf.reduce_mean(tf.nn.softplus(nlogit_sample + plogit_sample))\n",
    "\n",
    "def get_criterion(Tp, Tn):\n",
    "    return TwoWayLoss(Tp=Tp, Tn=Tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697e842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-4\n",
    "batch_size = 2**7\n",
    "num_epochs = 20\n",
    "patch_size = 6\n",
    "image_size = 32\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 2**6\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim\n",
    "] # Size of the transformer layers\n",
    "\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [\n",
    "    2 ** 11,\n",
    "    2 ** 10,\n",
    "] # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ff3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc9c96c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patches):\n",
    "        positions = tf.expand_dims(\n",
    "            tf.range(start=0, limit=self.num_patches, delta=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patches)\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0366533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier(num_classes=40):\n",
    "    encoded_patches = keras.Input(shape=INPUT_SHAPE)\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    model = keras.Model(inputs=encoded_patches, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5b766",
   "metadata": {},
   "source": [
    "# Add index to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfaf4ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(546, 40, 64)\n"
     ]
    }
   ],
   "source": [
    "N = 546  \n",
    "num_patches = 40  \n",
    "height = 20  \n",
    "width = 20  \n",
    "channels = 1  \n",
    "projection_dim = 64  \n",
    "\n",
    "patches = images_list\n",
    "\n",
    "patches = tf.reshape(patches, (N, num_patches, height * width * channels))\n",
    "\n",
    "encoder = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim)\n",
    "encoded_patches = encoder(patches)\n",
    "print(encoded_patches.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6715b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "nINF = -100.0\n",
    "\n",
    "class TwoWayLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, Tp=4.0, Tn=1.0, name=\"two_way_loss\"):\n",
    "        super().__init__(name=name)\n",
    "        self.Tp = Tp\n",
    "        self.Tn = Tn\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Convert y_true and y_pred to tensors\n",
    "        y_true = tf.convert_to_tensor(y_true)\n",
    "        y_pred = tf.convert_to_tensor(y_pred)\n",
    "\n",
    "        # Create masks to identify positive and negative samples\n",
    "        class_mask = tf.reduce_any(y_true > 0, axis=0)\n",
    "        sample_mask = tf.reduce_any(y_true > 0, axis=1)\n",
    "\n",
    "        # Calculate hard positive logits\n",
    "        pmask = tf.where(y_true > 0, 0.0, nINF)\n",
    "        plogit_class = tf.reduce_logsumexp(-y_pred / self.Tp + pmask, axis=0) * self.Tp\n",
    "        plogit_class = tf.boolean_mask(plogit_class, class_mask)\n",
    "        plogit_sample = tf.reduce_logsumexp(-y_pred / self.Tp + pmask, axis=1) * self.Tp\n",
    "        plogit_sample = tf.boolean_mask(plogit_sample, sample_mask)\n",
    "    \n",
    "        # Calculate hard negative logits\n",
    "        nmask = tf.where(y_true == 0, 0.0, nINF)\n",
    "        nlogit_class = tf.reduce_logsumexp(y_pred / self.Tn + nmask, axis=0) * self.Tn\n",
    "        nlogit_class = tf.boolean_mask(nlogit_class, class_mask)\n",
    "        nlogit_sample = tf.reduce_logsumexp(y_pred / self.Tn + nmask, axis=1) * self.Tn\n",
    "        nlogit_sample = tf.boolean_mask(nlogit_sample, sample_mask)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = tf.reduce_mean(tf.nn.softplus(nlogit_class + plogit_class)) + \\\n",
    "               tf.reduce_mean(tf.nn.softplus(nlogit_sample + plogit_sample))\n",
    "        return loss\n",
    "\n",
    "def get_criterion():\n",
    "    return TwoWayLoss(Tp=4.0, Tn=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9400bb38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 06:23:08.584522: I external/local_xla/xla/service/service.cc:168] XLA service 0x7efb340c5b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-18 06:23:08.584550: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-06-18 06:23:08.584572: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-06-18 06:23:08.589289: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718691788.684198 2718641 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 13s - loss: 22.8940 - multi_label_accuracy: 0.1715WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 3s 9ms/step - loss: 20.9821 - multi_label_accuracy: 0.2147\n",
      "Epoch 2/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 19.3646 - multi_label_accuracy: 0.2453WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 18.7109 - multi_label_accuracy: 0.2857\n",
      "Epoch 3/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 18.8420 - multi_label_accuracy: 0.3236WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 18.0643 - multi_label_accuracy: 0.3467\n",
      "Epoch 4/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 18.2682 - multi_label_accuracy: 0.3703WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.9472 - multi_label_accuracy: 0.3726\n",
      "Epoch 5/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.9380 - multi_label_accuracy: 0.3902WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.6948 - multi_label_accuracy: 0.3895\n",
      "Epoch 6/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 16.9739 - multi_label_accuracy: 0.3930WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.5308 - multi_label_accuracy: 0.3986\n",
      "Epoch 7/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.5845 - multi_label_accuracy: 0.3896WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.5342 - multi_label_accuracy: 0.4192\n",
      "Epoch 8/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.8995 - multi_label_accuracy: 0.4059WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.4681 - multi_label_accuracy: 0.4260\n",
      "Epoch 9/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 18.1276 - multi_label_accuracy: 0.4447WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.4526 - multi_label_accuracy: 0.4217\n",
      "Epoch 10/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.4667 - multi_label_accuracy: 0.4057WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.3544 - multi_label_accuracy: 0.4196\n",
      "Epoch 11/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 18.2430 - multi_label_accuracy: 0.4225WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.3694 - multi_label_accuracy: 0.4248\n",
      "Epoch 12/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.5710 - multi_label_accuracy: 0.4191WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.2159 - multi_label_accuracy: 0.4436\n",
      "Epoch 13/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.6574 - multi_label_accuracy: 0.4059WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.2041 - multi_label_accuracy: 0.4264\n",
      "Epoch 14/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.9733 - multi_label_accuracy: 0.4135WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.3371 - multi_label_accuracy: 0.4249\n",
      "Epoch 15/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.8637 - multi_label_accuracy: 0.4246WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.2482 - multi_label_accuracy: 0.4239\n",
      "Epoch 16/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 18.6366 - multi_label_accuracy: 0.4199WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.3856 - multi_label_accuracy: 0.4344\n",
      "Epoch 17/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.5674 - multi_label_accuracy: 0.4164WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.2439 - multi_label_accuracy: 0.4295\n",
      "Epoch 18/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 18.0228 - multi_label_accuracy: 0.4447WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.2771 - multi_label_accuracy: 0.4337\n",
      "Epoch 19/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 16.7810 - multi_label_accuracy: 0.4100WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.2541 - multi_label_accuracy: 0.4294\n",
      "Epoch 20/20\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 17.8738 - multi_label_accuracy: 0.4289WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_f1_score` which is not available. Available metrics are: loss,multi_label_accuracy\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 17.2831 - multi_label_accuracy: 0.4319\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (40, 64)\n",
    "train_size = len(images_list)\n",
    "initial_learning_rate = 0.001\n",
    "final_learning_rate = 0.00001\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate) ** (1 / num_epochs)\n",
    "steps_per_epoch = int(train_size/batch_size)\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim\n",
    "]\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=initial_learning_rate,\n",
    "                decay_steps=steps_per_epoch,\n",
    "                decay_rate=learning_rate_decay_factor,\n",
    "                staircase=True)\n",
    "\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=lr_schedule, weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "model = create_vit_classifier()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=get_criterion(),\n",
    "    metrics=[\n",
    "        multi_label_accuracy\n",
    "    ],\n",
    ")\n",
    "\n",
    "weight_filename = str(datetime.datetime.now().strftime(\"%d %b %Y %I:%M%p\")) + '__checkpoint.weights.h5'\n",
    "checkpoint_filepath = \"ViT_weights/\" + str(weight_filename)\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor=\"val_f1_score\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    ")\n",
    "f1_early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_f1_score',\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "history = model.fit(\n",
    "    encoded_patches,\n",
    "    labels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[checkpoint_callback,\n",
    "               f1_early_stopping_callback],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
